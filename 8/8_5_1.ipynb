{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8-5-1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4hmKTxC6Ocv",
        "colab_type": "code",
        "outputId": "65347607-77f4-4881-ab8e-9ec8d3b39dde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "\n",
        "latent_dim = 32\n",
        "height = 32\n",
        "width = 32\n",
        "channels = 3\n",
        "\n",
        "# 생성자 (None, 32) \n",
        "generator_input = keras.Input(shape=(latent_dim,))\n",
        "\n",
        "# (None, 32) * (32, 32768) = (None, 32768)\n",
        "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "# (None, 32768) => (None, 16, 16, 128)\n",
        "x = layers.Reshape((16, 16, 128))(x)\n",
        "\n",
        "# (None, 16, 16, 128) * (128, 256) => (None, 16, 16, 256)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "# 32* 32 크기로 업샘플림? 어떻게? - 스트라이드 크기만큼 곱한 크기로 이미지를 늘린다.\n",
        "# (None, 16, 16, 256) => (None, 32, 32, 256)\n",
        "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "# (None, 32, 32, 256) * (256, 3) = (None, 32, 32, 3) \n",
        "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
        "generator = keras.models.Model(generator_input, x)\n",
        "generator.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32768)             1081344   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 256)       819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 3)         37635     \n",
            "=================================================================\n",
            "Total params: 6,264,579\n",
            "Trainable params: 6,264,579\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCQuH_DA7Se0",
        "colab_type": "code",
        "outputId": "33e40a3d-113c-4012-cc5b-3111eb47011b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "# 판별자\n",
        "discriminator_input = layers.Input(shape=(height, width, channels))\n",
        "\n",
        "x = layers.Conv2D(128, 3)(discriminator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "x = layers.Dropout(0.4)(x)\n",
        "\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "discriminator = keras.models.Model(discriminator_input, x)\n",
        "discriminator.summary()\n",
        "\n",
        "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\n",
        "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 14, 14, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 6, 6, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 2, 2, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 790,913\n",
            "Trainable params: 790,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2beME0DAOKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator.trainable = False\n",
        "\n",
        "#gan의 인풋과 아웃풋은 판별자이다.\n",
        "gan_input = keras.Input(shape=(latent_dim,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = keras.models.Model(gan_input, gan_output)\n",
        "\n",
        "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
        "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTY0nH0LlSpT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "5c47b3c5-1b61-42ce-e65f-fee9a96da2ea"
      },
      "source": [
        "import os\n",
        "from keras.preprocessing import image\n",
        "\n",
        "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# select forg image (number 6)\n",
        "x_train = x_train[y_train.flatten() == 5]\n",
        "\n",
        "# data normalize\n",
        "x_train = x_train.reshape((x_train.shape[0],) + (height, width, channels)).astype('float32') / 255.\n",
        "\n",
        "iterations = 10000\n",
        "batch_size = 20\n",
        "save_dir = './'\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "  os.mkdir(save_dir)\n",
        "\n",
        "start = 0\n",
        "for step in range(iterations):\n",
        "  # generate random noise\n",
        "  random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "\n",
        "  # decoding fake image\n",
        "  generated_images = generator.predict(random_latent_vectors)\n",
        "\n",
        "  # connect real image\n",
        "  stop = start + batch_size\n",
        "  real_images = x_train[start: stop]\n",
        "  combined_images = np.concatenate([generated_images, real_images])\n",
        "\n",
        "  # 진짜와 가짜 이미지를 구분하여 레이블을 합침\n",
        "  labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
        "\n",
        "  # !important - add noise at labels \n",
        "  labels += 0.05 * np.random.random(labels.shape)\n",
        "\n",
        "  # train discriminator\n",
        "  d_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "\n",
        "  random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "\n",
        "  # 모두 진짜 이미지라고 레이블을 만듬\n",
        "  misleading_targets = np.zeros((batch_size, 1))\n",
        "\n",
        "  # generator 훈련 - 가중치는 동결됨 \n",
        "  a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
        "\n",
        "  \n",
        "\n",
        "  start += batch_size\n",
        "  if start > len(x_train) - batch_size:\n",
        "    start = 0\n",
        "  if step % 100 == 0:\n",
        "    gan.save_weights('gan.h5')\n",
        "\n",
        "    print('판별자 손실: ', d_loss)\n",
        "    print('적대적 손실: ', a_loss)\n",
        "\n",
        "    img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
        "    img.save(os.path.join(save_dir, 'generated_frog' + str(step) + '.png'))\n",
        "\n",
        "    img = image.array_to_img(real_images[0] * 255., scale= False)\n",
        "    img.save(os.path.join(save_dir, 'real_frog' + str(step) + '.png'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "판별자 손실:  0.699224\n",
            "적대적 손실:  0.67299926\n",
            "판별자 손실:  0.64197624\n",
            "적대적 손실:  0.84674025\n",
            "판별자 손실:  0.57149047\n",
            "적대적 손실:  1.8651257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gISYx-5Grzpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}